{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V9atvmd99CKv"
      },
      "outputs": [],
      "source": [
        "!pip install chromadb transformers torch\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModel\n",
        "import torch\n",
        "import numpy as np\n",
        "import chromadb\n",
        "from chromadb.config import Settings\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "# Function to load the model and tokenizer\n",
        "def load_model_and_tokenizer(model_name):\n",
        "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "    model = AutoModel.from_pretrained(model_name)\n",
        "    return tokenizer, model\n",
        "\n",
        "# Function to generate embeddings\n",
        "def generate_embeddings(texts, tokenizer, model):\n",
        "    embeddings = []\n",
        "    for text in texts:\n",
        "        inputs = tokenizer(text, return_tensors=\"pt\")\n",
        "        with torch.no_grad():\n",
        "            outputs = model(**inputs)\n",
        "        embedding = outputs.last_hidden_state.mean(dim=1).squeeze().numpy()\n",
        "        embeddings.append(embedding)\n",
        "    return np.array(embeddings)\n",
        "\n",
        "# Function to store embeddings in ChromaDB\n",
        "def store_embeddings_in_chromadb(embeddings, texts, collection_name=\"text_embeddings\"):\n",
        "    settings = Settings()\n",
        "    client = chromadb.Client(settings)\n",
        "    collection = client.create_collection(collection_name)\n",
        "    for text, embedding in zip(texts, embeddings):\n",
        "        collection.add(id=text, embedding=embedding.tolist())\n",
        "    return client, collection\n",
        "\n",
        "# Function to query embeddings from ChromaDB\n",
        "def query_embeddings(collection, query_text, tokenizer, model):\n",
        "    query_embedding = generate_embeddings([query_text], tokenizer, model)[0].tolist()\n",
        "    results = collection.find_similar(embedding=query_embedding, top_k=5)\n",
        "    return results\n",
        "\n",
        "# Function to evaluate embeddings\n",
        "def evaluate_embeddings(embeddings):\n",
        "    cosine_sim_matrix = cosine_similarity(embeddings)\n",
        "    return cosine_sim_matrix\n",
        "\n",
        "# Example texts\n",
        "texts = [\"This is an example sentence.\", \"This is another sentence.\"]\n",
        "\n",
        "# Load model and tokenizer\n",
        "model_name = \"huggingface-e5-base\"\n",
        "tokenizer, model = load_model_and_tokenizer(model_name)\n",
        "\n",
        "# Generate embeddings\n",
        "embeddings = generate_embeddings(texts, tokenizer, model)\n",
        "print(\"Embeddings generated successfully.\")\n",
        "\n",
        "# Store embeddings in ChromaDB\n",
        "client, collection = store_embeddings_in_chromadb(embeddings, texts)\n",
        "print(\"Embeddings stored in ChromaDB successfully.\")\n",
        "\n",
        "# Query embeddings from ChromaDB\n",
        "query_text = \"This is an example sentence.\"\n",
        "results = query_embeddings(collection, query_text, tokenizer, model)\n",
        "\n",
        "# Display results\n",
        "for result in results:\n",
        "    print(f\"Text: {result['embedding_id']}, Similarity: {result['similarity']}\")\n",
        "\n",
        "# Evaluate embeddings\n",
        "cosine_sim_matrix = evaluate_embeddings(embeddings)\n",
        "print(\"Cosine similarity matrix calculated successfully.\")\n",
        "print(cosine_sim_matrix)\n"
      ],
      "metadata": {
        "id": "poD_hTJZ9M4P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1IxgEOh09QgC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CwKX3pXQ9M60"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "a2NOo_Pm9M9E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MxbKGuJA9M_L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dvWF4VZk9NBm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "AiVqQkL49NDj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RegRcFRN9NFz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gTM6IP3s9NIF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lCT8Vg6Q9NKe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Zq7f1frL9NMr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ecbunHEy9NRM"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}